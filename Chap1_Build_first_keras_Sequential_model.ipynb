{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kM8KutYLuM-dm4KBV79_BeT6kw1iFVQ9",
      "authorship_tag": "ABX9TyMYbV1pHiULoYsIFnQVanw5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhbao1705/Keras-tutorial/blob/main/Chap1_Build_first_keras_Sequential_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Sequential model is a linear stack of layers\n",
        "\n",
        "You can create a Sequential model by passing a list of layer instances to the constructor"
      ],
      "metadata": {
        "id": "33s3U5-xXXfm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfbmT_JPipYP"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(32, input_shape=(784, )),\n",
        "    Activation('relu'),\n",
        "    Dense(10),\n",
        "    Activation('softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "2QAy1z8rXwtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also simply add layers via the .add() method"
      ],
      "metadata": {
        "id": "OTAbkY4cYTDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=784))\n",
        "model.add(Activation('relu'))"
      ],
      "metadata": {
        "id": "fFMrVWUMYRvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Specifying the input shape**\n",
        "The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape. There are several possible ways to do this:\n",
        "\n",
        "* Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or None entries, where None indicates that any positive integer may be expected). In input_shape, the batch dimension is not included.\n",
        "* Some 2D layers, such as Dense, support the specification of their input shape via the argument input_dim, and some 3D temporal layers support the arguments input_dim and input_length.\n",
        "* If you ever need to specify a fixed batch size for your inputs (this is useful for stateful recurrent networks), you can pass a batch_size argument to a layer. If you pass both batch_size=32 and input_shape=(6, 8) to a layer, it will then expect every batch of inputs to have the batch shape (32, 6, 8).\n",
        "\n",
        "As such, the following snippets are strictly equivalent:"
      ],
      "metadata": {
        "id": "rIaMgmu6ZVqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_shape=(784, )))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=784))"
      ],
      "metadata": {
        "id": "CLzWJbs4YgMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compilation**\n",
        "Before training a model, you need to configure the learning process, which is done via the compile method. It receives three arguments:\n",
        "\n",
        "* An optimizer. This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Opimizer class.\n",
        "* A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (suchs as categorical_crossentropy or mse), or it can be objective function.\n",
        "* A list of metrics. FOr any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function."
      ],
      "metadata": {
        "id": "OUUHhZ59aiY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For a multi-class classification problem\n",
        "model.compile(optimizer='rmsprop',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# For a binary classification problem\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# For a mean squared error regression problem\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mse')\n",
        "\n",
        "# For custom metrics\n",
        "import keras.backend as K\n",
        "\n",
        "def mean_pred(y_true, y_pred):\n",
        "  return K.mean(y_pred)\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', mean_pred])"
      ],
      "metadata": {
        "id": "huA1NhXmaWHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**\n",
        "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the fit function. Read its documentation here"
      ],
      "metadata": {
        "id": "kvDgvOdkdbaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For a single-input model with 2 class (binary classification)\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_classification',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate numpy data\n",
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(2, size=(1000, 1))\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, labels, epochs=10, batch_size=32)\n",
        "\n",
        "# For a single-input model with 10 classes (categorical classification)\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=100))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generator numpy data\n",
        "import numpy as np\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(10, size=(1000, 1))\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "pH6xoEUndAcX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}